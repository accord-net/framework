// Accord Imaging Library
// The Accord.NET Framework
// http://accord-framework.net
//
// Copyright © César Souza, 2009-2017
// cesarsouza at gmail.com
//
//    This library is free software; you can redistribute it and/or
//    modify it under the terms of the GNU Lesser General Public
//    License as published by the Free Software Foundation; either
//    version 2.1 of the License, or (at your option) any later version.
//
//    This library is distributed in the hope that it will be useful,
//    but WITHOUT ANY WARRANTY; without even the implied warranty of
//    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
//    Lesser General Public License for more details.
//
//    You should have received a copy of the GNU Lesser General Public
//    License along with this library; if not, write to the Free Software
//    Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA
//

namespace Accord.Imaging
{
    using Accord.MachineLearning;
    using Accord.Math;
    using System;
    using System.Collections.Generic;
    using System.Drawing;
    using System.IO;
    using System.Threading;
    using System.Linq;
    using Accord.Compat;
    using System.Threading.Tasks;
    using System.Collections.Concurrent;

    /// <summary>
    ///   Base class for Bag of Visual Words implementations.
    /// </summary>
    /// 
    [Serializable]
    public class BaseBagOfVisualWords<TModel, TPoint, TFeature, TClustering, TDetector> :
        // TODO: Unify with Accord.MachineLearning.BaseBagOfWords
        ParallelLearningBase,
        IBagOfWords<Bitmap>,
        IBagOfWords<UnmanagedImage>,
        IUnsupervisedLearning<TModel, Bitmap, int[]>,
        IUnsupervisedLearning<TModel, Bitmap, double[]>,
        IUnsupervisedLearning<TModel, UnmanagedImage, int[]>,
        IUnsupervisedLearning<TModel, UnmanagedImage, double[]>
        where TPoint : IFeatureDescriptor<TFeature>
        where TModel : BaseBagOfVisualWords<TModel, TPoint, TFeature, TClustering, TDetector>
        //where TClustering : IClusteringAlgorithm<TFeature>
        where TClustering : IUnsupervisedLearning<IClassifier<TFeature, int>, TFeature, int>
        where TDetector : IFeatureDetector<TPoint, TFeature>
    {

        private IClassifier<TFeature, int> classifier;

        /// <summary>
        ///   Gets the number of words in this codebook.
        /// </summary>
        /// 
        public int NumberOfWords { get; private set; }

        /// <summary>
        ///   Gets the clustering algorithm used to create this model.
        /// </summary>
        /// 
        public TClustering Clustering { get; private set; }

        /// <summary>
        ///   Gets the <see cref="SpeededUpRobustFeaturesDetector">SURF</see>
        ///   feature point detector used to identify visual features in images.
        /// </summary>
        /// 
        public TDetector Detector { get; private set; }

        /// <summary>
        /// Gets the number of inputs accepted by the model.
        /// </summary>
        /// <value>The number of inputs.</value>
        public int NumberOfInputs
        {
            get { return -1; }
            set { throw new InvalidOperationException("This property is read-only."); }
        }

        /// <summary>
        /// Gets the number of outputs generated by the model.
        /// </summary>
        /// <value>The number of outputs.</value>
        public int NumberOfOutputs
        {
            get { return NumberOfWords; }
            set { throw new InvalidOperationException("This property is read-only."); }
        }

        /// <summary>
        ///   Constructs a new <see cref="BagOfVisualWords"/>.
        /// </summary>
        /// 
        protected BaseBagOfVisualWords()
        {
        }

        /// <summary>
        ///   Initializes this instance.
        /// </summary>
        /// 
        protected void Init(TDetector detector, TClustering algorithm)
        {
            this.Clustering = algorithm;
            this.Detector = detector;
        }

        internal KMeans KMeans(int numberOfWords)
        {
            return new KMeans(numberOfWords)
            {
                ComputeCovariances = false,
                UseSeeding = Seeding.KMeansPlusPlus,
                ParallelOptions = ParallelOptions
            };
        }


        #region Obsolete

        /// <summary>
        ///   Computes the Bag of Words model.
        /// </summary>
        /// 
        /// <param name="images">The set of images to initialize the model.</param>
        /// 
        /// <returns>The list of feature points detected in all images.</returns>
        /// 
        [Obsolete("Please use the Learn() method instead.")]
        public List<TPoint>[] Compute(Bitmap[] images)
        {
            var descriptors = new ConcurrentBag<TFeature>();
            var imagePoints = new List<TPoint>[images.Length];

            // For all images
            Parallel.For(0, images.Length, ParallelOptions,
                () => (IFeatureDetector<TPoint, TFeature>)Detector.Clone(),
                (i, state, detector) =>
                {
                    // Compute the feature points
                    IEnumerable<TPoint> points = detector.ProcessImage(images[i]);
                    foreach (IFeatureDescriptor<TFeature> point in points)
                        descriptors.Add(point.Descriptor);

                    imagePoints[i] = (List<TPoint>)points;
                    return detector;
                },
                (detector) => detector.Dispose());

            Learn(descriptors.ToArray());

            return imagePoints;
        }

        /// <summary>
        ///   Computes the Bag of Words model.
        /// </summary>
        /// 
        /// <param name="features">The extracted image features to initialize the model.</param>
        /// 
        /// <returns>The list of feature points detected in all images.</returns>
        /// 
        [Obsolete("Please use the Learn() method instead.")]
        public void Compute(TFeature[] features)
        {
            Learn(features);
        }

        /// <summary>
        ///   Computes the Bag of Words model.
        /// </summary>
        /// 
        /// <param name="images">The set of images to initialize the model.</param>
        /// <param name="threshold">Convergence rate for the k-means algorithm. Default is 1e-5.</param>
        /// 
        /// <returns>The list of feature points detected in all images.</returns>
        /// 
        [Obsolete("Please configure the tolerance of the clustering algorithm directly in the "
            + "algorithm itself by accessing it through the Clustering property of this class.")]
        public List<TPoint>[] Compute(Bitmap[] images, double threshold)
        {
            // Hack to maintain backwards compatibility
            var prop = Clustering.GetType().GetProperty("Tolerance");
            if (prop != null && prop.CanWrite)
                prop.SetValue(Clustering, threshold, null);

            return Compute(images);
        }

        /// <summary>
        ///   Gets the codeword representation of a given image.
        /// </summary>
        /// 
        /// <param name="value">The image to be processed.</param>
        /// 
        /// <returns>A double vector with the same length as words
        /// in the code book.</returns>
        /// 
        [Obsolete("Please use the Transform() method instead.")]
        public double[] GetFeatureVector(Bitmap value)
        {
            return Transform(value);
        }

        /// <summary>
        ///   Gets the codeword representation of a given image.
        /// </summary>
        /// 
        /// <param name="value">The image to be processed.</param>
        /// 
        /// <returns>A double vector with the same length as words
        /// in the code book.</returns>
        /// 
        [Obsolete("Please use the Transform() method instead.")]
        public double[] GetFeatureVector(UnmanagedImage value)
        {
            return Transform(value);
        }

        /// <summary>
        ///   Gets the codeword representation of a given image.
        /// </summary>
        /// 
        /// <param name="points">The interest points of the image.</param>
        /// 
        /// <returns>A double vector with the same length as words
        /// in the code book.</returns>
        /// 
        [Obsolete("Please use the Transform() method instead.")]
        public double[] GetFeatureVector(List<TPoint> points)
        {
            return Transform(points);
        }

        /// <summary>
        ///   Saves the bag of words to a stream.
        /// </summary>
        /// 
        /// <param name="stream">The stream to which the bow is to be serialized.</param>
        /// 
        [Obsolete("Please use Accord.IO.Serializer.Save() instead (or use it as an extension method).")]
        public virtual void Save(Stream stream)
        {
            Accord.IO.Serializer.Save(this, stream);
        }

        /// <summary>
        ///   Saves the bag of words to a file.
        /// </summary>
        /// 
        /// <param name="path">The path to the file to which the bow is to be serialized.</param>
        /// 
        [Obsolete("Please use Accord.IO.Serializer.Save() instead (or use it as an extension method).")]

        public void Save(string path)
        {
            Accord.IO.Serializer.Save(this, path);
        }

        #endregion



        #region Transform

        /// <summary>
        /// Applies the transformation to a set of input vectors,
        /// producing an associated set of output vectors.
        /// </summary>
        /// <param name="input">The input data to which
        /// the transformation should be applied.</param>
        /// <param name="result">The location to where to store the
        /// result of this transformation.</param>
        /// <returns>The output generated by applying this
        /// transformation to the given input.</returns>
        public int[] Transform(IList<TPoint> input, int[] result)
        {
            // Detect all activation centroids
            Parallel.For(0, input.Count, ParallelOptions, i =>
            {
                TFeature x = input[i].Descriptor;
                int j = classifier.Decide(x);
                Interlocked.Increment(ref result[j]);
            });

            return result;
        }

        /// <summary>
        /// Applies the transformation to a set of input vectors,
        /// producing an associated set of output vectors.
        /// </summary>
        /// <param name="input">The input data to which
        /// the transformation should be applied.</param>
        /// <param name="result">The location to where to store the
        /// result of this transformation.</param>
        /// <returns>The output generated by applying this
        /// transformation to the given input.</returns>
        public double[] Transform(IList<TPoint> input, double[] result)
        {
            // Detect all activation centroids
            Parallel.For(0, input.Count, ParallelOptions, i =>
            {
                TFeature x = input[i].Descriptor;
                int j = classifier.Decide(x);
                InterlockedEx.Increment(ref result[j]);
            });

            return result;
        }


        /// <summary>
        /// Applies the transformation to a set of input vectors,
        /// producing an associated set of output vectors.
        /// </summary>
        /// <param name="input">The input data to which
        /// the transformation should be applied.</param>
        /// <param name="result">The location to where to store the
        /// result of this transformation.</param>
        /// <returns>The output generated by applying this
        /// transformation to the given input.</returns>
        public double[] Transform(Bitmap input, double[] result)
        {
            return Transform((List<TPoint>)Detector.ProcessImage(input), result);
        }

        /// <summary>
        /// Applies the transformation to a set of input vectors,
        /// producing an associated set of output vectors.
        /// </summary>
        /// <param name="input">The input data to which
        /// the transformation should be applied.</param>
        /// <param name="result">The location to where to store the
        /// result of this transformation.</param>
        /// <returns>The output generated by applying this
        /// transformation to the given input.</returns>
        public int[] Transform(Bitmap input, int[] result)
        {
            return Transform((List<TPoint>)Detector.ProcessImage(input), result);
        }

        /// <summary>
        /// Applies the transformation to a set of input vectors,
        /// producing an associated set of output vectors.
        /// </summary>
        /// <param name="input">The input data to which
        /// the transformation should be applied.</param>
        /// <param name="result">The location to where to store the
        /// result of this transformation.</param>
        /// <returns>The output generated by applying this
        /// transformation to the given input.</returns>
        public double[] Transform(UnmanagedImage input, double[] result)
        {
            return Transform((List<TPoint>)Detector.ProcessImage(input), result);
        }

        /// <summary>
        /// Applies the transformation to a set of input vectors,
        /// producing an associated set of output vectors.
        /// </summary>
        /// <param name="input">The input data to which
        /// the transformation should be applied.</param>
        /// <param name="result">The location to where to store the
        /// result of this transformation.</param>
        /// <returns>The output generated by applying this
        /// transformation to the given input.</returns>
        public int[] Transform(UnmanagedImage input, int[] result)
        {
            return Transform((List<TPoint>)Detector.ProcessImage(input), result);
        }


        /// <summary>
        /// Applies the transformation to an input, producing an associated output.
        /// </summary>
        /// <param name="input">The input data to which the transformation should be applied.</param>
        /// <returns>The output generated by applying this transformation to the given input.</returns>
        public double[] Transform(List<TPoint> input)
        {
            return Transform(input, new double[NumberOfWords]);
        }

        /// <summary>
        /// Applies the transformation to an input, producing an associated output.
        /// </summary>
        /// <param name="input">The input data to which the transformation should be applied.</param>
        /// <returns>The output generated by applying this transformation to the given input.</returns>
        public double[] Transform(Bitmap input)
        {
            return Transform(input, new double[NumberOfWords]);
        }

        int[] ITransform<Bitmap, int[]>.Transform(Bitmap input)
        {
            return Transform(input, new int[NumberOfWords]);
        }

        /// <summary>
        /// Applies the transformation to an input, producing an associated output.
        /// </summary>
        /// <param name="input">The input data to which the transformation should be applied.</param>
        /// <returns>The output generated by applying this transformation to the given input.</returns>
        public double[] Transform(UnmanagedImage input)
        {
            return Transform(input, new double[NumberOfWords]);
        }


        int[] ITransform<UnmanagedImage, int[]>.Transform(UnmanagedImage input)
        {
            return Transform(input, new int[NumberOfWords]);
        }





        /// <summary>
        /// Applies the transformation to a set of input vectors,
        /// producing an associated set of output vectors.
        /// </summary>
        /// <param name="input">The input data to which
        /// the transformation should be applied.</param>
        /// <returns>The output generated by applying this
        /// transformation to the given input.</returns>
        public double[][] Transform(UnmanagedImage[] input)
        {
            return Transform(input, Jagged.Zeros<double>(input.Length, NumberOfWords));
        }

        int[][] ITransform<UnmanagedImage, int[]>.Transform(UnmanagedImage[] input)
        {
            return Transform(input, Jagged.Zeros<int>(input.Length, NumberOfWords));
        }

        /// <summary>
        /// Applies the transformation to a set of input vectors,
        /// producing an associated set of output vectors.
        /// </summary>
        /// <param name="input">The input data to which
        /// the transformation should be applied.</param>
        /// <returns>The output generated by applying this
        /// transformation to the given input.</returns>
        public double[][] Transform(Bitmap[] input)
        {
            return Transform(input, Jagged.Zeros(input.Length, NumberOfWords));
        }

        int[][] ITransform<Bitmap, int[]>.Transform(Bitmap[] input)
        {
            return Transform(input, Jagged.Zeros<int>(input.Length, NumberOfWords));
        }


        /// <summary>
        ///   Executes a parallel for using the feature detector in a thread-safe way.
        /// </summary>
        private void For(int fromInclusive, int toExclusive,
            Action<int, IFeatureDetector<TPoint, TFeature>> action)
        {
            if (ParallelOptions.MaxDegreeOfParallelism == 1)
            {
                for (int i = fromInclusive; i < toExclusive; i++)
                    action(i, Detector);
                return;
            }

            Parallel.For(fromInclusive, toExclusive, ParallelOptions,

                // If we don't clone the detector, we run in race conditions
                () => (IFeatureDetector<TPoint, TFeature>)Detector.Clone(),

                (i, state, detector) =>
                {
                    // here, each thread has its own copy of the detector
                    action(i, detector);
                    return detector;
                },

                (detector) => detector.Dispose());
        }

        /// <summary>
        /// Applies the transformation to a set of input vectors,
        /// producing an associated set of output vectors.
        /// </summary>
        /// <param name="input">The input data to which
        /// the transformation should be applied.</param>
        /// <param name="result">The location to where to store the
        /// result of this transformation.</param>
        /// <returns>The output generated by applying this
        /// transformation to the given input.</returns>
        public double[][] Transform(Bitmap[] input, double[][] result)
        {
            For(0, input.Length, (i, detector) =>
                Transform((IList<TPoint>)detector.ProcessImage(input[i]), result[i]));
            return result;
        }

        /// <summary>
        /// Applies the transformation to a set of input vectors,
        /// producing an associated set of output vectors.
        /// </summary>
        /// <param name="input">The input data to which
        /// the transformation should be applied.</param>
        /// <param name="result">The location to where to store the
        /// result of this transformation.</param>
        /// <returns>The output generated by applying this
        /// transformation to the given input.</returns>
        public int[][] Transform(Bitmap[] input, int[][] result)
        {
            For(0, input.Length, (i, detector) =>
                 Transform((IList<TPoint>)detector.ProcessImage(input[i]), result[i]));

            return result;
        }

        /// <summary>
        /// Applies the transformation to a set of input vectors,
        /// producing an associated set of output vectors.
        /// </summary>
        /// <param name="input">The input data to which
        /// the transformation should be applied.</param>
        /// <param name="result">The location to where to store the
        /// result of this transformation.</param>
        /// <returns>The output generated by applying this
        /// transformation to the given input.</returns>
        public int[][] Transform(UnmanagedImage[] input, int[][] result)
        {
            For(0, input.Length, (i, detector) =>
                 Transform((IList<TPoint>)detector.ProcessImage(input[i]), result[i]));

            return result;
        }

        /// <summary>
        /// Applies the transformation to a set of input vectors,
        /// producing an associated set of output vectors.
        /// </summary>
        /// <param name="input">The input data to which
        /// the transformation should be applied.</param>
        /// <param name="result">The location to where to store the
        /// result of this transformation.</param>
        /// <returns>The output generated by applying this
        /// transformation to the given input.</returns>
        public double[][] Transform(UnmanagedImage[] input, double[][] result)
        {
            For(0, input.Length, (i, detector) =>
                 Transform((IList<TPoint>)detector.ProcessImage(input[i]), result[i]));

            return result;
        }

        #endregion



        #region Learn

        /// <summary>
        /// Learns a model that can map the given inputs to the desired outputs.
        /// </summary>
        /// <param name="x">The model inputs.</param>
        /// <param name="weights">The weight of importance for each input sample.</param>
        /// <returns>A model that has learned how to produce suitable outputs
        /// given the input data <paramref name="x" />.</returns>
        public TModel Learn(Bitmap[] x, double[] weights = null)
        {
            // Note: See note in the method below
            var descriptors = new TFeature[x.Length][];

            // For all images
            For(0, x.Length, (i, detector) =>
            {
                // Compute the feature points
                descriptors[i] = detector.ProcessImage(x[i]).Select(p => p.Descriptor).ToArray();
            });

            return Learn(descriptors.Concatenate());
        }

        /// <summary>
        /// Learns a model that can map the given inputs to the desired outputs.
        /// </summary>
        /// <param name="x">The model inputs.</param>
        /// <param name="weights">The weight of importance for each input sample.</param>
        /// <returns>A model that has learned how to produce suitable outputs
        /// given the input data <paramref name="x" />.</returns>
        public TModel Learn(UnmanagedImage[] x, double[] weights = null)
        {
            // Note: we cannot use a ConcurrentBag here to store all the descriptors because
            // it would break the reproducibility of the clustering algorithm that is run
            // after this step. The point is that the ConcurrentBag cannot guarantee order of
            // insertion (since we are using parallel code) and this would cause the clustering
            // algorithm to initialize with arbitrary points even the random seeds were fixed.
            var descriptors = new TFeature[x.Length][];

            // For all images
            For(0, x.Length, (i, detector) =>
            {
                // Compute the feature points
                descriptors[i] = detector.ProcessImage(x[i]).Select(p => p.Descriptor).ToArray();
            });

            return Learn(descriptors.Concatenate());
        }

        /// <summary>
        /// Learns a model that can map the given inputs to the desired outputs.
        /// </summary>
        /// <param name="x">The model inputs.</param>
        /// <param name="weights">The weight of importance for each input sample.</param>
        /// <returns>A model that has learned how to produce suitable outputs
        /// given the input data <paramref name="x" />.</returns>
        public TModel Learn(TFeature[] x, double[] weights = null)
        {
            if (x.Length <= NumberOfWords)
            {
                throw new InvalidOperationException("Not enough data points to cluster. Please try "
                    + "to adjust the feature extraction algorithm to generate more points.");
            }

            this.classifier = this.Clustering.Learn(x, weights);
            this.NumberOfWords = this.classifier.NumberOfClasses;

            return (TModel)this;
        }

        #endregion
    }
}
